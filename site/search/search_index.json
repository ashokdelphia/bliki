{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Owen Jacobson \u00b6 Hire Me . I've been a professional software developer since the early 2000s and an enthusiastic amateur even longer, and a manager of developers since 2019. I'm also deeply interested in organizational dynamics and group consensus: software, like ourselves, lives in a society, and both serves the needs of and serves to help shape that society. Code . I program computers. I have done so all of my adult life, and expect to do so as long as I can string concepts together. Like many lifelong programmers, I periodically write up interesting things I've developed, collaborated on, or run across. My larger projects are on Github . Papers of Note . Computer science and development-adjacent papers and academic works I encourage people to read. Gossamer . In 2014, long before Mastodon was in any kind of widespread use, I sketched out an idea for a fully-distributed status sharing network based on Twitter, but without the weakness of the Twitter, Inc. corporation. I've preserved the writeup here, as it's an excellent case study in how blindness to social violence can lead to dangerous software design. Gossamer should never be implemented , because it would put vulnerable users at extreme risk . In 2020, with Mastodon well established and the shape of distributed status networks much more widely understood, a friend pushed me to revisit the idea . The best way to contact me is by email , but I'm present in many places . If you prefer that your mail not be read by others, my GPG key fingerprint is 77BDC4F16EFD607E85AAB63950232991F10DFFD0.","title":"Owen Jacobson"},{"location":"#owen-jacobson","text":"Hire Me . I've been a professional software developer since the early 2000s and an enthusiastic amateur even longer, and a manager of developers since 2019. I'm also deeply interested in organizational dynamics and group consensus: software, like ourselves, lives in a society, and both serves the needs of and serves to help shape that society. Code . I program computers. I have done so all of my adult life, and expect to do so as long as I can string concepts together. Like many lifelong programmers, I periodically write up interesting things I've developed, collaborated on, or run across. My larger projects are on Github . Papers of Note . Computer science and development-adjacent papers and academic works I encourage people to read. Gossamer . In 2014, long before Mastodon was in any kind of widespread use, I sketched out an idea for a fully-distributed status sharing network based on Twitter, but without the weakness of the Twitter, Inc. corporation. I've preserved the writeup here, as it's an excellent case study in how blindness to social violence can lead to dangerous software design. Gossamer should never be implemented , because it would put vulnerable users at extreme risk . In 2020, with Mastodon well established and the shape of distributed status networks much more widely understood, a friend pushed me to revisit the idea . The best way to contact me is by email , but I'm present in many places . If you prefer that your mail not be read by others, my GPG key fingerprint is 77BDC4F16EFD607E85AAB63950232991F10DFFD0.","title":"Owen Jacobson"},{"location":"hire-me/","text":"Hire Me \u00b6 I'm always interested in hearing from people and organizations that I can help, whether that means coming in for a few days to talk about end-to-end testing or joining your organization full-time to help turn an idea into reality. I live in and around Toronto. I am more than happy to work remotely, and I can probably help your organization learn to integrate remote work if it doesn't already know how. For Fun \u00b6 I regularly mentor people new to programming, teaching them how to craft working systems. This is less about teaching people to write code and more about teaching them why we care about source control, how to think about configuration, how to and why to automate testing, and how to think about software systems and data flow at a higher level. I strongly believe that software development needs a formal apprenticeship program, and mentoring has done a lot to validate that belief. Heroku/Salesforce (2015-Present) \u00b6 In my time with Heroku (and with Salesforce, Heroku's parent organization), I've contributed to the operation of services that let developers bring their ideas to life on the internet, both as a developer and as a manager. I've been involved in maintaining and expanding existing features, exploring and developing new products, and in cultivating my peers and my team as people and as developers. As an engineering manager, I've been responsible for building and supporting an effective, unified team. Moving into management was motivated by a desire to act as a force multiplier, which I've brought to life through coaching, process management, facilitating ongoing discussions about the direction and health of the team, and through actively being involved in my reports' progress as developers. As a lead developer, I worked on the Heroku build system , which ingests code from end users and deploys that code to applications running on the Heroku platform. As part of that work, we implemented a number of features to control abuse, support language-specific features and needs, and to develop new ways to deploy code to Heroku. FreshBooks (2009-2014) \u00b6 During the five years I was with the company, it grew from a 20-person one-room organization to a healthy, growing two-hundred-person technology company. As an early employee, I had my hand in many, many projects and helped the development team absorb the massive cultural changes that come with growth, while also building a SaaS product that let others realize their dreams. Some highlights: As the lead database administrator-slash-developer, I worked with the entire development team to balance concerns about reliability and availability with ensuring new ideas and incremental improvements could be executed without massive bureaucracy and at low risk. This extended into diverse parts of the company: alongside the operations team, I handled capacity planning, reliability, outage planning, and performance monitoring, while with the development team, I was responsible for designing processes and deploying tools to ease testing of database changes and ensuring smooth, predictable, and low-effort deployment to production and for training developers to make the best use of MySQL for their projects. As a tools developer, I built the Sparkplug framework to standardize the tools and processes for building message-driven applications, allowing the team to move away from monolithic web applications towards a more event-driven suite of interal systems. Providing a standard framework paid off well; building and deploying completely novel event handlers for FreshBooks\u2019 core systems could be completed in as little as a week, including testing and production provisioning. As an ops-ish toolsmith, I worked extensively on configuration management for both applications and the underlying servers. I lead a number of projects to reduce the risk around deployments: creating a standard development VM to ensure developers had an environment consistent with reality, automating packaging and rollout to testing servers, automating the creation of testing servers, and more. As part of this work, I built training materials and ran sessions to teach other developers how to think like a sysadmin, covering Linux, Puppet, virtualization, and other topics. Riptown Media (2006-2009) \u00b6 Riptown Media was an software development company tasked with building and maintaining a suite of gambling systems for a single client. I was brought on board as a Java developer, and rapidly expanded my role to encompass other fields. As the primary developer for poker-room back office and anti-fraud tools, I worked with the customer support and business intelligence teams to better understand their daily needs and frustrations, so that I could turn those into meaningful improvements to their tools and processes. These improvements, in turn, lead to measurable changes in the frequency and length of customer support calls, in fraud rates, and in the percieved value of internal customer intelligence. As a lead developer, my team put together the server half of an in-house casino gaming platform. We worked in tight collaboration with the client team, in-house and third-party testers, and interaction designers, and delivered our first game in under six months. Our platform was meant to reduce our reliance on third-party \u201cwhite label\u201d games vendors; internally, it was a success. Our game received zero customer-reported defects during its initial run. OSI Geospatial (2004-2006) \u00b6 At OSI Geospatial, I lead the development of a target-tracking and battlespace awareness overlay as part of a suite of operational theatre tools. In 2004, the state of the art for web-based geomatics software was not up to the task; this ended up being a custom server written in C++ and making heavy use of PostgreSQL and PostGIS for its inner workings. Contact Me \u00b6 You can get in touch by email at owen@grimoire.ca. I'd love to hear from you.","title":"Hire Me"},{"location":"hire-me/#hire-me","text":"I'm always interested in hearing from people and organizations that I can help, whether that means coming in for a few days to talk about end-to-end testing or joining your organization full-time to help turn an idea into reality. I live in and around Toronto. I am more than happy to work remotely, and I can probably help your organization learn to integrate remote work if it doesn't already know how.","title":"Hire Me"},{"location":"hire-me/#for-fun","text":"I regularly mentor people new to programming, teaching them how to craft working systems. This is less about teaching people to write code and more about teaching them why we care about source control, how to think about configuration, how to and why to automate testing, and how to think about software systems and data flow at a higher level. I strongly believe that software development needs a formal apprenticeship program, and mentoring has done a lot to validate that belief.","title":"For Fun"},{"location":"hire-me/#herokusalesforce-2015-present","text":"In my time with Heroku (and with Salesforce, Heroku's parent organization), I've contributed to the operation of services that let developers bring their ideas to life on the internet, both as a developer and as a manager. I've been involved in maintaining and expanding existing features, exploring and developing new products, and in cultivating my peers and my team as people and as developers. As an engineering manager, I've been responsible for building and supporting an effective, unified team. Moving into management was motivated by a desire to act as a force multiplier, which I've brought to life through coaching, process management, facilitating ongoing discussions about the direction and health of the team, and through actively being involved in my reports' progress as developers. As a lead developer, I worked on the Heroku build system , which ingests code from end users and deploys that code to applications running on the Heroku platform. As part of that work, we implemented a number of features to control abuse, support language-specific features and needs, and to develop new ways to deploy code to Heroku.","title":"Heroku/Salesforce (2015-Present)"},{"location":"hire-me/#freshbooks-2009-2014","text":"During the five years I was with the company, it grew from a 20-person one-room organization to a healthy, growing two-hundred-person technology company. As an early employee, I had my hand in many, many projects and helped the development team absorb the massive cultural changes that come with growth, while also building a SaaS product that let others realize their dreams. Some highlights: As the lead database administrator-slash-developer, I worked with the entire development team to balance concerns about reliability and availability with ensuring new ideas and incremental improvements could be executed without massive bureaucracy and at low risk. This extended into diverse parts of the company: alongside the operations team, I handled capacity planning, reliability, outage planning, and performance monitoring, while with the development team, I was responsible for designing processes and deploying tools to ease testing of database changes and ensuring smooth, predictable, and low-effort deployment to production and for training developers to make the best use of MySQL for their projects. As a tools developer, I built the Sparkplug framework to standardize the tools and processes for building message-driven applications, allowing the team to move away from monolithic web applications towards a more event-driven suite of interal systems. Providing a standard framework paid off well; building and deploying completely novel event handlers for FreshBooks\u2019 core systems could be completed in as little as a week, including testing and production provisioning. As an ops-ish toolsmith, I worked extensively on configuration management for both applications and the underlying servers. I lead a number of projects to reduce the risk around deployments: creating a standard development VM to ensure developers had an environment consistent with reality, automating packaging and rollout to testing servers, automating the creation of testing servers, and more. As part of this work, I built training materials and ran sessions to teach other developers how to think like a sysadmin, covering Linux, Puppet, virtualization, and other topics.","title":"FreshBooks (2009-2014)"},{"location":"hire-me/#riptown-media-2006-2009","text":"Riptown Media was an software development company tasked with building and maintaining a suite of gambling systems for a single client. I was brought on board as a Java developer, and rapidly expanded my role to encompass other fields. As the primary developer for poker-room back office and anti-fraud tools, I worked with the customer support and business intelligence teams to better understand their daily needs and frustrations, so that I could turn those into meaningful improvements to their tools and processes. These improvements, in turn, lead to measurable changes in the frequency and length of customer support calls, in fraud rates, and in the percieved value of internal customer intelligence. As a lead developer, my team put together the server half of an in-house casino gaming platform. We worked in tight collaboration with the client team, in-house and third-party testers, and interaction designers, and delivered our first game in under six months. Our platform was meant to reduce our reliance on third-party \u201cwhite label\u201d games vendors; internally, it was a success. Our game received zero customer-reported defects during its initial run.","title":"Riptown Media (2006-2009)"},{"location":"hire-me/#osi-geospatial-2004-2006","text":"At OSI Geospatial, I lead the development of a target-tracking and battlespace awareness overlay as part of a suite of operational theatre tools. In 2004, the state of the art for web-based geomatics software was not up to the task; this ended up being a custom server written in C++ and making heavy use of PostgreSQL and PostGIS for its inner workings.","title":"OSI Geospatial (2004-2006)"},{"location":"hire-me/#contact-me","text":"You can get in touch by email at owen@grimoire.ca. I'd love to hear from you.","title":"Contact Me"},{"location":"papers/","text":"Papers of Note \u00b6 Perlman, Radia (1985). \u201c An Algorithm for Distributed Computation of a Spanning Tree in an Extended LAN \u201d. ACM SIGCOMM Computer Communication Review. 15 (4): 44\u201353. doi:10.1145/318951.319004. The related Algorhyme , also by Perlman. Guy Lewis Steele, Jr.. \u201c Debunking the 'Expensive Procedure Call' Myth, or, Procedure Call Implementations Considered Harmful, or, Lambda: The Ultimate GOTO \u201d. MIT AI Lab. AI Lab Memo AIM-443. October 1977. What Every Computer Scientist Should Know About Floating-Point Arithmetic , by David Goldberg, published in the March, 1991 issue of Computing Surveys. Copyright 1991, Association for Computing Machinery, Inc. RFC 1925 . Regular Expression Matching Can Be Simple And Fast , Russ Cox's empirical research into degenerate cases in common regular expression implementations and a proposed implementation based on Thomson's NFA construction. The above-cited Thomson NFA paper on regular expressions. The Eight Fallacies of Distributed Computing . HAKMEM is another good one. It's dense but rewarding. Kahan, William (January 1965), \u201c Further remarks on reducing truncation errors \u201d, Communications of the ACM, 8 (1): 40, doi:10.1145/363707.363723","title":"Papers of Note"},{"location":"papers/#papers-of-note","text":"Perlman, Radia (1985). \u201c An Algorithm for Distributed Computation of a Spanning Tree in an Extended LAN \u201d. ACM SIGCOMM Computer Communication Review. 15 (4): 44\u201353. doi:10.1145/318951.319004. The related Algorhyme , also by Perlman. Guy Lewis Steele, Jr.. \u201c Debunking the 'Expensive Procedure Call' Myth, or, Procedure Call Implementations Considered Harmful, or, Lambda: The Ultimate GOTO \u201d. MIT AI Lab. AI Lab Memo AIM-443. October 1977. What Every Computer Scientist Should Know About Floating-Point Arithmetic , by David Goldberg, published in the March, 1991 issue of Computing Surveys. Copyright 1991, Association for Computing Machinery, Inc. RFC 1925 . Regular Expression Matching Can Be Simple And Fast , Russ Cox's empirical research into degenerate cases in common regular expression implementations and a proposed implementation based on Thomson's NFA construction. The above-cited Thomson NFA paper on regular expressions. The Eight Fallacies of Distributed Computing . HAKMEM is another good one. It's dense but rewarding. Kahan, William (January 1965), \u201c Further remarks on reducing truncation errors \u201d, Communications of the ACM, 8 (1): 40, doi:10.1145/363707.363723","title":"Papers of Note"},{"location":"code/","text":"Code \u00b6 Pieces of code and code-adjacent work, with or without exposition, that don't quite fit into the library ecosystem, but which I enjoyed writing. A Users, Roles & Privileges Scheme Using Graphs \u2014 An SQL schema and associated queries for handling permissions when roles can nest arbitrarily. Configuring Browser Apps \u2014 Notes on the available techniques for delivering runtime configuration to code running in a user's browser, and the tradeoffs involved. Writing Good Commit Messages \u2014 A style guide. I also maintain a Github account for more substantial projects.","title":"Code"},{"location":"code/#code","text":"Pieces of code and code-adjacent work, with or without exposition, that don't quite fit into the library ecosystem, but which I enjoyed writing. A Users, Roles & Privileges Scheme Using Graphs \u2014 An SQL schema and associated queries for handling permissions when roles can nest arbitrarily. Configuring Browser Apps \u2014 Notes on the available techniques for delivering runtime configuration to code running in a user's browser, and the tradeoffs involved. Writing Good Commit Messages \u2014 A style guide. I also maintain a Github account for more substantial projects.","title":"Code"},{"location":"code/commit-messages/","text":"Writing Good Commit Messages \u00b6 Rule zero: \u201cgood\u201d is defined by the standards of the project you're on. Have a look at what the existing messages look like, and try to emulate that first before doing anything else. Having said that, here are some principles I've found helpful and broadly applicable. Treat the first line of the message as a one-sentence summary. Most SCM systems have an \u201coverview\u201d command that shows shortened commit messages in bulk, so making the very beginning of the message meaningful helps make those modes more useful for finding specific commits. It's okay for this to be a \u201cwhat\u201d description if the rest of the message is a \u201cwhy\u201d description. Fill out the rest of the message with prose outlining why you made the change. Don't reiterate the contents of the change in great detail if you can avoid it: anyone who needs that can read the diff themselves, or reach out to ask for help understanding the change. A good rationale sets context for the problem being solved and addresses the ways the proposed change alters that context. If you use an issue tracker (and you should), include whatever issue-linking notes it supports right at the start of the message, where it'll be visible even in summarized commit logs. If your tracker has absurdly long issue-linking syntax, or doesn't support issue links in commits at all, include a short issue identifier at the front of the message and put the long part somewhere out of the way, such as on a line of its own at the end of the message. If you need rich commit messages (links, lists, and so on), pick one markup language and stick with it. It'll be easier to write useful commit formatters if you only have to deal with one syntax, rather than four. Personally, I use Markdown when I can, or a reduced subset of Markdown, as it's something most developers I interact with will be at least passing familiar with.","title":"Writing Good Commit Messages"},{"location":"code/commit-messages/#writing-good-commit-messages","text":"Rule zero: \u201cgood\u201d is defined by the standards of the project you're on. Have a look at what the existing messages look like, and try to emulate that first before doing anything else. Having said that, here are some principles I've found helpful and broadly applicable. Treat the first line of the message as a one-sentence summary. Most SCM systems have an \u201coverview\u201d command that shows shortened commit messages in bulk, so making the very beginning of the message meaningful helps make those modes more useful for finding specific commits. It's okay for this to be a \u201cwhat\u201d description if the rest of the message is a \u201cwhy\u201d description. Fill out the rest of the message with prose outlining why you made the change. Don't reiterate the contents of the change in great detail if you can avoid it: anyone who needs that can read the diff themselves, or reach out to ask for help understanding the change. A good rationale sets context for the problem being solved and addresses the ways the proposed change alters that context. If you use an issue tracker (and you should), include whatever issue-linking notes it supports right at the start of the message, where it'll be visible even in summarized commit logs. If your tracker has absurdly long issue-linking syntax, or doesn't support issue links in commits at all, include a short issue identifier at the front of the message and put the long part somewhere out of the way, such as on a line of its own at the end of the message. If you need rich commit messages (links, lists, and so on), pick one markup language and stick with it. It'll be easier to write useful commit formatters if you only have to deal with one syntax, rather than four. Personally, I use Markdown when I can, or a reduced subset of Markdown, as it's something most developers I interact with will be at least passing familiar with.","title":"Writing Good Commit Messages"},{"location":"code/configuring-browser-apps/","text":"Configuring Browser Apps \u00b6 I've found myself in he unexpected situation of having to write a lot of browser apps/single page apps this year. I have some thoughts on configuration. Why Bother \u00b6 Centralize environment-dependent facts to simplify management & testing Make it easy to manage app secrets. @wlonk adds: \u201cSecrets\u201d? What this means in a browser app is a bit different. Which is unpleasantly true. In a freestanding browser app, a \u201csecret\u201d is only as secret as your users and their network connections choose to make it, i.e., not very secret at all. Maybe that should read \u201cmake it easy to manage app tokens and identities ,\u201d instead. Keep config data & API tokens out of app's source control Integration point for external config sources (Aerobatic, Heroku, etc) The forces described in 12 Factor App: Dependencies and, to a lesser extent, 12 Factor App: Configuration apply just as well to web client apps as they do to freestanding services. What Gets Configured \u00b6 Yes: Base URLs of backend services Tokens and client IDs for various APIs No: \u201cEnvironments\u201d (sorry, Ember folks - I know Ember thought this through carefully, but whole-env configs make it easy to miss settings in prod or test, and encourage patterns like \u201call devs use the same backends\u201d) Delivering Configuration \u00b6 There are a few ways to get configuration into the app. Globals \u00b6 <head> <script>window.appConfig = { \"FOO_URL\": \"https://foo.example.com/\", \"FOO_TOKEN\": \"my-super-secret-token\" };</script> <script src=\"/your/app.js\"></script> </head> Easy to consume: it's just globals, so window.appConfig.foo will read them. This requires some discipline to use well. Have to generate a script to set them. This can be a <script>window.appConfig = {some json}</script> tag or a standalone config script loaded with <script src=\"/config.js\"> Generating config scripts sets a minimum level of complexity for the deployment process: you either need a server to generate the script at request time, or a preprocessing step at deployment time. It's code generation, which is easy to do badly. I had originally proposed using JSON.stringify to generate a Javascript object literal, but this fails for any config values with </script> in them. That may be an unlikely edge case, but that only makes it a nastier trap for administrators. There are more edge cases . I strongly suspect that a hazard-free implementation requires a full-blown JS source generator. I had a look at building something out of escodegen and estemplate , but escodegen 's node version doesn't generate browser-safe code , so string literals with </script> or </head> in them still break the page, and converting javascript values into parse trees to feed to estemplate is some seriously tedious code. Data Attributes and Link Elements \u00b6 <head> <link rel=\"foo-url\" href=\"https://foo.example.com/\"> <script src=\"/your/app.js\" data-foo-token=\"my-super-secret-token\"></script> </head> Flat values only. This is probably a good thing in the grand, since flat configurations are easier to reason about and much easier to document, but it makes namespacing trickier than it needs to be for groups of related config values (URL + token for a single service, for example). Have to generate the DOM to set them. This is only practical given server-side templates or DOM rendering. You can't do this with bare nginx, unless you pre-generate pages at deployment time. Config API Endpoint \u00b6 fetch('/config') /* {\"FOO_URL\": \u2026, \"FOO_TOKEN\": \u2026} */ .then(response => response.json()) .then(json => someConfigurableService); Works even with \u201cdumb\u201d servers (nginx, CloudFront) as the endpoint can be a generated JSON file on disk. If you can generate files, you can generate a JSON endpoint. Requires an additional request to fetch the configuration, and logic for injecting config data into all the relevant configurable places in the code. This request can't happen until all the app code has loaded. It's very tempting to write the config to a global. This produces some hilarious race conditions. Cookies \u00b6 See for example clientconfig : var config = require('clientconfig'); Easy to consume given the right tools; tricky to do right from scratch. Requires server-side support to send the correct cookie. Some servers will allow you to generate the right cookie once and store it in a config file; others will need custom logic, which means (effectively) you need an app server. Cookies persist and get re-sent on subsequent requests, even if the server stops delivering config cookies. Client code has to manage the cookie lifecycle carefully (clientconfig does this automatically) Size limits constrain how much configuration you can do.","title":"Configuring Browser Apps"},{"location":"code/configuring-browser-apps/#configuring-browser-apps","text":"I've found myself in he unexpected situation of having to write a lot of browser apps/single page apps this year. I have some thoughts on configuration.","title":"Configuring Browser Apps"},{"location":"code/configuring-browser-apps/#why-bother","text":"Centralize environment-dependent facts to simplify management & testing Make it easy to manage app secrets. @wlonk adds: \u201cSecrets\u201d? What this means in a browser app is a bit different. Which is unpleasantly true. In a freestanding browser app, a \u201csecret\u201d is only as secret as your users and their network connections choose to make it, i.e., not very secret at all. Maybe that should read \u201cmake it easy to manage app tokens and identities ,\u201d instead. Keep config data & API tokens out of app's source control Integration point for external config sources (Aerobatic, Heroku, etc) The forces described in 12 Factor App: Dependencies and, to a lesser extent, 12 Factor App: Configuration apply just as well to web client apps as they do to freestanding services.","title":"Why Bother"},{"location":"code/configuring-browser-apps/#what-gets-configured","text":"Yes: Base URLs of backend services Tokens and client IDs for various APIs No: \u201cEnvironments\u201d (sorry, Ember folks - I know Ember thought this through carefully, but whole-env configs make it easy to miss settings in prod or test, and encourage patterns like \u201call devs use the same backends\u201d)","title":"What Gets Configured"},{"location":"code/configuring-browser-apps/#delivering-configuration","text":"There are a few ways to get configuration into the app.","title":"Delivering Configuration"},{"location":"code/configuring-browser-apps/#globals","text":"<head> <script>window.appConfig = { \"FOO_URL\": \"https://foo.example.com/\", \"FOO_TOKEN\": \"my-super-secret-token\" };</script> <script src=\"/your/app.js\"></script> </head> Easy to consume: it's just globals, so window.appConfig.foo will read them. This requires some discipline to use well. Have to generate a script to set them. This can be a <script>window.appConfig = {some json}</script> tag or a standalone config script loaded with <script src=\"/config.js\"> Generating config scripts sets a minimum level of complexity for the deployment process: you either need a server to generate the script at request time, or a preprocessing step at deployment time. It's code generation, which is easy to do badly. I had originally proposed using JSON.stringify to generate a Javascript object literal, but this fails for any config values with </script> in them. That may be an unlikely edge case, but that only makes it a nastier trap for administrators. There are more edge cases . I strongly suspect that a hazard-free implementation requires a full-blown JS source generator. I had a look at building something out of escodegen and estemplate , but escodegen 's node version doesn't generate browser-safe code , so string literals with </script> or </head> in them still break the page, and converting javascript values into parse trees to feed to estemplate is some seriously tedious code.","title":"Globals"},{"location":"code/configuring-browser-apps/#data-attributes-and-link-elements","text":"<head> <link rel=\"foo-url\" href=\"https://foo.example.com/\"> <script src=\"/your/app.js\" data-foo-token=\"my-super-secret-token\"></script> </head> Flat values only. This is probably a good thing in the grand, since flat configurations are easier to reason about and much easier to document, but it makes namespacing trickier than it needs to be for groups of related config values (URL + token for a single service, for example). Have to generate the DOM to set them. This is only practical given server-side templates or DOM rendering. You can't do this with bare nginx, unless you pre-generate pages at deployment time.","title":"Data Attributes and Link Elements"},{"location":"code/configuring-browser-apps/#config-api-endpoint","text":"fetch('/config') /* {\"FOO_URL\": \u2026, \"FOO_TOKEN\": \u2026} */ .then(response => response.json()) .then(json => someConfigurableService); Works even with \u201cdumb\u201d servers (nginx, CloudFront) as the endpoint can be a generated JSON file on disk. If you can generate files, you can generate a JSON endpoint. Requires an additional request to fetch the configuration, and logic for injecting config data into all the relevant configurable places in the code. This request can't happen until all the app code has loaded. It's very tempting to write the config to a global. This produces some hilarious race conditions.","title":"Config API Endpoint"},{"location":"code/configuring-browser-apps/#cookies","text":"See for example clientconfig : var config = require('clientconfig'); Easy to consume given the right tools; tricky to do right from scratch. Requires server-side support to send the correct cookie. Some servers will allow you to generate the right cookie once and store it in a config file; others will need custom logic, which means (effectively) you need an app server. Cookies persist and get re-sent on subsequent requests, even if the server stops delivering config cookies. Client code has to manage the cookie lifecycle carefully (clientconfig does this automatically) Size limits constrain how much configuration you can do.","title":"Cookies"},{"location":"code/users-rolegraph-privs/","text":"A Users, Roles & Privileges Scheme Using Graphs \u00b6 The basic elements: Every agent that can interact with a system is represented by a user . Every capability the system has is authorized by a distinct privilege . Each user has a list of zero or more roles . Roles can imply further roles. This relationship is transitive: if role A implies role B, then a member of role A is a member of role B; if role B also implies role C, then a member of role A is also a member of role C. It helps if the resulting role graph is acyclic, but it's not necessary. Roles can grant privileges. A user's privileges are the union of the privileges granted by the transitive closure of their roles. create table \"user\" ( username varchar primary key -- credentials &c ); create table role ( name varchar primary key ); create table role_member ( role varchar not null references role, member varchar not null references \"user\", primary key (role, member) ); create table role_implies ( role varchar not null references role, implied_role varchar not null ); create table privilege ( privilege varchar primary key ); create table role_grants ( role varchar not null references role, privilege varchar not null references privilege, primary key (role, privilege) ); If your database supports recursive CTEs, this schema can be queried in one shot, since we can have the database do all the graph-walking along roles: with recursive user_roles (role) AS ( select role from role_member where member = 'SOME USERNAME' union select implied_role as role from user_roles join role_implies on user_roles.role = role_implies.role ) select distinct role_grants.privilege as privilege from user_roles join role_grants on user_roles.role = role_grants.role order by privilege; If not, you'll need to pull the entire graph into memory and manipulate it there: this schema doesn't give you any easy handles to identify only the roles transitively included in the role of interest, and repeatedly querying for each step of the graph requires an IO roundtrip at each step, burning whole milliseconds along the way. Realistic use cases should have fairly simple graphs: elemental privileges are grouped into concrete roles, which are in turn grouped into abstracted roles (by department, for example), which are in turn granted to users. If the average user is in tens of roles and has hundreds of privileges, the entire dataset fits in memory, and PostgreSQL performs well. In PostgreSQL, the above schema handles ~10k privileges and ~10k roles with randomly-generated graph relationships in around 100ms on my laptop, which is pretty slow but not intolerable. Perverse cases (interconnected total subgraphs, deeply-nested linear graphs) can take absurd time but do not reflect any likely permissions scheme.","title":"A Users, Roles & Privileges Scheme Using Graphs"},{"location":"code/users-rolegraph-privs/#a-users-roles-privileges-scheme-using-graphs","text":"The basic elements: Every agent that can interact with a system is represented by a user . Every capability the system has is authorized by a distinct privilege . Each user has a list of zero or more roles . Roles can imply further roles. This relationship is transitive: if role A implies role B, then a member of role A is a member of role B; if role B also implies role C, then a member of role A is also a member of role C. It helps if the resulting role graph is acyclic, but it's not necessary. Roles can grant privileges. A user's privileges are the union of the privileges granted by the transitive closure of their roles. create table \"user\" ( username varchar primary key -- credentials &c ); create table role ( name varchar primary key ); create table role_member ( role varchar not null references role, member varchar not null references \"user\", primary key (role, member) ); create table role_implies ( role varchar not null references role, implied_role varchar not null ); create table privilege ( privilege varchar primary key ); create table role_grants ( role varchar not null references role, privilege varchar not null references privilege, primary key (role, privilege) ); If your database supports recursive CTEs, this schema can be queried in one shot, since we can have the database do all the graph-walking along roles: with recursive user_roles (role) AS ( select role from role_member where member = 'SOME USERNAME' union select implied_role as role from user_roles join role_implies on user_roles.role = role_implies.role ) select distinct role_grants.privilege as privilege from user_roles join role_grants on user_roles.role = role_grants.role order by privilege; If not, you'll need to pull the entire graph into memory and manipulate it there: this schema doesn't give you any easy handles to identify only the roles transitively included in the role of interest, and repeatedly querying for each step of the graph requires an IO roundtrip at each step, burning whole milliseconds along the way. Realistic use cases should have fairly simple graphs: elemental privileges are grouped into concrete roles, which are in turn grouped into abstracted roles (by department, for example), which are in turn granted to users. If the average user is in tens of roles and has hundreds of privileges, the entire dataset fits in memory, and PostgreSQL performs well. In PostgreSQL, the above schema handles ~10k privileges and ~10k roles with randomly-generated graph relationships in around 100ms on my laptop, which is pretty slow but not intolerable. Perverse cases (interconnected total subgraphs, deeply-nested linear graphs) can take absurd time but do not reflect any likely permissions scheme.","title":"A Users, Roles &amp; Privileges Scheme Using Graphs"},{"location":"gossamer/","text":"Gossamer: A Decentralized Status-Sharing Network \u00b6 Twitter's pretty great. The short format encourages brief, pithy remarks, and the default assumption of visibility makes it super easy to pitch in on a conversation, or to find new people to listen to. Unfortunately, Twitter is a centralized system: one Bay-area company in the United States controls and mediates all Twitter interactions. From all appearances, Twitter, Inc. is relatively benign, as social media corporations go. There are few reports of censorship, and while their response to abuse of the Twitter network has not been consistently awesome, they can be made to listen. However, there exists the capacity for Twitter, Inc. to subvert the entire Twitter system, either voluntarily or at the behest of governments around the world. (Just ask Turkish people. Or the participants in the Arab Spring.) Gossamer is a Twitter-alike system, designed from the ground up to have no central authority. It resists censorship, enables individual participants to control their own data, and allows anyone at all to integrate new software into the Gossamer network. Gossamer does not exist, but if it did, the following notes describe what it might look like, and the factors to consider when implementing Gossamer as software. I have made fatal mistakes while writing it; I have not rushed to build it specifically because Twitter, Gossamer's model, is so deeply woven into so many peoples' lives. A successor must make fewer mistakes, not merely different mistakes, and certainly not more mistakes. The following is loosely inspired by Rumor Monger , at \u201cwhole world\u201d scale. Design Goals \u00b6 Users must be in control of their own privacy and identity at all times. (This is a major failing with Diaspora, which limits access to personal ownership of data by being hard to run.) Users must be able to communicate without the consent or support of an intermediate authority. Short of being completely offline, Gossamer should be resilient to infrastructural damage. Any functional communication system will be used for illicit purposes. This is an unavoidable consequence of being usable for legitimate purposes without a central authority. Rather than revealing illicit conversations, Gossamer should do what it can to preserve the anonymity and privacy of legitimate ones. All nodes are as equal as possible. The node I use is not more authoritative for messages from me than any other node. You can hear my words from anyone who has heard my words, and I can hear yours from anyone who has heard your words, so long as some variety of authenticity and privacy are maintained. If an identity's secrets are removed, a node should contain no data that correlates the owner with his or her Gossamer identities. Relaying and authoring must be as indistinguishable as possible, to limit the utility of traffic analysis. Public and Private Information \u00b6 Every piece of data Gossamer uses, either internally or to communicate with other ndoes, is classified as either public or private . Public information can be communicated to other nodes, and is assumed to be safe if recovered out of band. Private information includes anything which may be used to associate a Gossamer identity with the person who controls it, except as noted below. Gossamer must ensure users understand what information that they provide will be made public, and what will be kept private, so that they can better decide what, if anything, to share and so that they can better make decisions about their own safety and comfort against abusive parties. Internally, Gossamer always stores private information encrypted, and never transmits it to another node. Gossamer must provide a tool to safely obliterate private data. Public Information \u00b6 Details on the role of each piece of information are covered below. Public status updates, obviously. Gossamer exists to permit users to easily share short messages with one another. The opaque form of a user's incoming and outgoing private messages. The users' identities' public keys. (But not their relationship to one another.) Any information the user places in their profile. (This implies that profiles must not be auto-populated from, for example, the user's address book.) The set of identities verified by the user's identity. Any other information Gossamer retains must be private. Republishing \u00b6 Gossamer is built on the assumption that every participant is willing to act as a relay for every other participant. This is a complicated assumption at the human layer. Inevitably, someone will use the Gossamer network to communicate something morally repugnant or deeply illegal: the Silk Road guy, for example, got done for trying to contract someone to commit murder. Every Gossamer node is complicit in delivering those messages to the rest of the network, whether they're in the clear (status updates) or not (private messages). It's unclear how this interacts with the various legal frameworks, moral codes, and other social constructs throughout the world, and it's ethically troubling to put users in that position by default. The strong alternative, that each node only relay content with the controlling user's explicit and ongoing consent, is also troubling: it limits the Gossamer network's ability to deliver messages at all , and exposes information about which identities each node's owner considers interesting and publishable. I don't have an obvious resolution to this. Gossamer's underlying protocol relies on randomly-selected nodes being more likely to propagate a message than to ignore it, because this helps make Gossamer resilient to hostile users, nosy intelligence agencies, and others who believe communication must be restrictable. On the other hand, I'd like not to put a user in Taiwan at risk of legal or social reprisals because a total stranger in Canada decided to post something vile. (This is one of the reasons I haven't built the damn thing yet. Besides being A Lot Of Code, there's no way to shut off Gossamer once more than one node exists, and I want to be sure I've thought through what I'm doing before creating a prototype.) Identity in the Gossamer Network \u00b6 Every Gossamer message carries with it an identity . Gossamer identities are backed by public-key cryptography. However, unlike traditional public key systems such as GPG, Gossamer identities provide continuity , rather than authenticity : two Gossamer messages signed by the same key are from the same identity, but there is no inherent guarantee that that identity is legitimate. Gossamer maintains relationships between identities to allow users to verify the identities of one another, and to publish attestations of that to other Gossamer nodes. From this, Gossamer can recover much of GPG's \u201cweb of trust.\u201d TODO : revocation of identities, revocation of verifications. Both are important; novice users are likely to verify people poorly, and there should be a recovery path less drastic than GPG's \u201cyou swore it, you're stuck with it\u201d model. Gossamer encourages users to create additional identities as needed to, for example, support the separation of work and home conversations, or to provide anonymity when discussing reputationally-hazardous topics. Identities are not correlated by the Gossamer codebase. Each identity can optionally include a profile : a block of data describing the person behind the identity. The contents of a profile are chosen by the person holding the private key for an identity, and the profile is attached to every new message created with the corresponding identity. A user can update their profile at will; potentially, every message can be sent with a distinct profile. Gossamer software treats the profile it's seen with the highest timestamp as authoritative, retroactively applying it to old messages. Multiple Devices and Key Security \u00b6 A Gossamer identity is entirely contained in its private key. An identity's key must be stored safely, either using the host operating system's key management facilities or using a carefully-designed key store. Keys must not hit long-term storage unprotected; this may involve careful integration with the underlying OS's memory management facilities to avoid, eg., placing identities in swap. This is necessary to protect users from having their identities recovered against their will via, for example, hard drive forensics. Gossamer allows keys to be exported into password-encrypted archive files, which can be loaded into other Gossamer applications to allow them to share the same identity. GOSSAMER MUST TREAT THESE FILES WITH EXTREME CARE, BECAUSE USERS PROBABLY WON'T . Identity keys protect the user's Gossamer identity, but they also protect the user's private messages (see below) and other potentially identifying data. The export format must be designed to be as resilient as possible, and Gossamer's software must take care to ensure that \u201cused\u201d identity files are automatically destroyed safely wherever possible and to discourage users from following practices that weaken their own safety unknowingly. Exported identity files are intrinsically vulnerable to offline brute-force attacks; once obtained, an attacker can try any of the worryingly common passwords at will, and can easily validate a password by using the recovered keys to regenerate some known fact about the original, such as a verification or a message signature. This implies that exported identities must use a key derivation system which has a high computational cost and which is believed to be resilient to, for example, GPU-accelerated cracking. Secure deletion is a Hard Problem; where possible, Gossamer must use operating system-provided facilities for securely destroying files. Status Messages \u00b6 Status messages are messages visible to any interested Gossamer users. These are the primary purpose of Gossamer. Each contains up to 140 Unicode characters, a markup section allowing Gossamer to attach URLs and metadata (including Gossamer locators) to the text, and an attachments section carrying arbitrary MIME blobs of limited total size. All three sections are canonicalized ( TODO : how?) and signed by the publishing identity's private key. The public key, the identity's most recent profile, and the signed status message are combined into a single Gossamer message and injected into the user's Gossamer node exactly as if it had arrived from another node. Each Gossamer node maintains a follow list of identities whose messages the user is interested in seeing. When Gossamer receives a novel status message during a gossip exchange, it displays it to the user if and only if its identity is on the node's follow list. Otherwise, the message is not displayed, but will be shared onwards with other nodes. In this way, every Gossamer node acts as a relay for every other Gossamer node. If Gossamer receives a message signed by an identity it has seen attestations for, it attaches those attestations to the message before delivering them onwards. In this way, users' verifications of one another's identity spread through the network organically. Private Messages \u00b6 Gossamer can optionally encrypt messages, allowing users to send one another private messages. These messages are carried over the Gossamer network as normal, but only nodes holding the appropriate identity key can decrypt them and display them to the user. (At any given time, most Gossamer nodes hold many private messages they cannot decrypt.) Private messages do not carry the author's identity or full profile in the clear. The author's bare identity is included in the encrypted part of the message, to allow the intended recipient to identify the sender. TODO : sign-then-encrypt, or encrypt-then-sign? If sign-then-encrypt, are private messages exempted from the \u201cdrop broken messages\u201d rule above? Following Users \u00b6 Each Gossamer node maintains a database of followed identities. (This may or may not include the owner's own identity.) Any message stored in the node published by an identity in this database will be shown to the user in a timeline-esque view. Gossamer's follow list is purely local , and is not shared between nodes even if they have identities in common. The follow list is additionally stored encrypted using the node's identities (any one identity is sufficient to recover the list), to ensure that the follow list is not easily available to others without the node owner's permission. Exercises such as Finding Paul Revere have shown that the collection of graph edges showing who communicates with whom can often be sufficient to map identities into people. Gossamer attempts to restrict access to this data, believing it is not the network's place to know who follows who. Verified Identities \u00b6 Gossamer allows identities to sign one anothers' public keys. These signatures form verifications . Gossamer considers an identity verified if any of the following hold: Gossamer has access to the identity key for the identity itself. Gossamer has access to the identity key for at least one of the identity's verifications. The identity is signed by at least three (todo: or however many, I didn't do the arithmetic yet) verified identities. Verified identities are marked in the user interface to make it obvious to the user whether a message is from a known friend or from an unknown identity. Gossamer allows users to sign new verifications for any identity they have seen. These verifications are initially stored locally, but will be published as messages transit the node as described below. Verification is a public fact: everyone can see which identities have verified which other identities. This is a potentially very powerful tool for reassociating identities with real-world people; Gossamer must make this clear to users. (I'm pretty sure you could find me, personally, just by watching whose identities I verify.) Each Gossamer node maintains a database of every verification it has ever seen or generated. If the node receives a message from an identity that appears in the verification database, and if the message is under some total size, Gossamer appends verifications from its database to the message before reinjecting it into the network. This allows verifications to propagate through Blocking Users \u00b6 Any social network will attract hostile users who wish to disrupt the network or abuse its participants. Users must be able to filter out these users, and must not provide too much feedback to blocked users that could otherwise be used to circumvent blocks. Each Gossamer node maintains a database of blocked identities. Any message from an identity in this database, or from an identity that is verified by three or more identities in this database, will automatically be filtered out from display. (Additionally, transitively-blocked users will automatically be added to the block database. Blocking is contagious.) ( TODO : should Gossamer drop blocked messages? How does that interact with the inevitable \u201cshared blocklist\u201d systems that arise in any social network?) As with the follow list, the block database is encrypted using the node's identities. Gossamer encourages users to create new identities as often as they see fit and attempts to separate identities from one another as much as possible. This is fundamentally incompatible with strong blocking. It will always be possible for a newly-created identity to deliver at least one message before being blocked. This is a major design problem ; advice encouraged. Gossamer Network Primitives \u00b6 The Gossamer network is built around a gossip protocol, wherein nodes connect to one another periodically to exchange messages with one another. Connections occur over the existing IP internet infrastructure, traversing NAT networks where possible to ensure that users on residential and corporate networks can still participate. Gossamer bootstraps its network using a number of paths: Gossamer nodes in the same broadcast domain discover one another using UDP broadcasts as well as Bonjour/mDNS. Gossamer can generate locator strings, which can be shared \u201cout of band\u201d via email, SMS messages, Twitter, graffiti, etc. Gossamer nodes share knowledge of nodes whenever they exchange messages, to allow the Gossamer network to recover from lost nodes and to permit nodes to remain on the network as \u201cknown\u201d nodes are lost to outages and entropy. Locators \u00b6 A Gossamer locator is a URL in the g scheme, carrying an encoding of one or more network addresses as well as an encoding of one or more identities (see below). Gossamer's software attempts to determine an appropriate identifier for any identities it holds based on the host computer's network configuration, taking into account issues like NAT traversal wherever possible. TODO : Gossamer and uPNP, what do locators look like? When presented with an identifier, Gossamer offers to follow the identities it contains, and uses the nodes whose addresses it contains to connect to the Gossamer network. This allows new clients to bootstrap into Gossamer, and provides an easy way for users to exchange Gossamer identities to connect to one another later. (Clever readers will note that the address list is actually independent of the identity list.) Gossip \u00b6 Each Gossamer node maintains a pair of \u201cfreshness\u201d databases, associating some information with a freshness score (expressed as an integer). One freshness database holds the addresses of known Gossamer nodes, and another holds Gossamer messages. Whenever two Gossamer nodes interact, each sends the other a Gossamer node from its current node database, and a message from its message database. When selecting an item to send for either category, Gossamer uses a random selection that weights towards items with a higher \u201cfreshness\u201d score. ( TODO : how?) When sending a fact, if the receiving node already knows the fact, both nodes decrement that fact's freshness by one. If the receiving node does not already know the fact, the sending node leaves its freshness unaltered, and the receiving node sets its freshness to the freshest possible value. This system encourages nodes to exchange \u201cfresh\u201d facts, then cease exchanging them as the network becomes aware of them. During each exchange, Gossamer nodes send each other one Gossamer node address, and one Gossamer message. Both nodes adjust their freshness databases, as above. If fact exchange fails while communicating with a Gossamer node, both nodes decrement their peer's freshness. Unreliable nodes can continue to initiate connections to other nodes, but will rarely be contacted by other Gossamer nodes. TODO : How do we avoid DDOSing brand-new gossamer nodes with the full might of Gossamer's network? TODO : Can we reuse Bittorrent's DHT system (BEP-5) to avoid having every node know the full network topology? TODO : Are node-to-node exchanges encrypted? If so, why and how? Authenticity \u00b6 Gossamer node addresses are not authenticated. Gossamer relies on freshness to avoid delivering excess traffic to systems not participating in the Gossamer network. ( TODO : this is a shit system for avoiding DDOS, though.) Gossamer messages are partially authenticated: each carries with it a public key, and a signature. If the signature cannot be verified with the included public key, it must be discarded immediately and it must not be propagated to other nodes. The node delivering the message may also be penalized by having its freshness reduced in the receiving node's database. Gossip Triggers \u00b6 Gossamer triggers a new Gossip exchange under the following circumstances: 15 seconds, plus a random jitter between zero and 15 more seconds, elapse since the last exchange attempt. Gossamer completes an exchange wherein it learned a new fact from another node. A user injects a fact into Gossamer directly. Gossamer exchanges that fail, or that deliver only already-known facts, do not trigger further exchanges immediately. TODO : how do we prevent Gossamer from attempting to start an unbounded number of exchanges at the same time? Size \u00b6 Gossamer must not exhaust the user's disk. Gossamer discards extremely un-fresh messages, attempting to keep the on-disk size of the message database to under 10% of the total local storage, or under a user-configurable threshold. Gossamer rejects over-large messages. Public messages carry with them the author's profile and a potentially large collection of verifications. Messages over some size ( TODO what size?) are discarded on receipt without being stored, and the message exchange is considered to have failed.","title":"Gossamer: A Decentralized Status-Sharing Network"},{"location":"gossamer/#gossamer-a-decentralized-status-sharing-network","text":"Twitter's pretty great. The short format encourages brief, pithy remarks, and the default assumption of visibility makes it super easy to pitch in on a conversation, or to find new people to listen to. Unfortunately, Twitter is a centralized system: one Bay-area company in the United States controls and mediates all Twitter interactions. From all appearances, Twitter, Inc. is relatively benign, as social media corporations go. There are few reports of censorship, and while their response to abuse of the Twitter network has not been consistently awesome, they can be made to listen. However, there exists the capacity for Twitter, Inc. to subvert the entire Twitter system, either voluntarily or at the behest of governments around the world. (Just ask Turkish people. Or the participants in the Arab Spring.) Gossamer is a Twitter-alike system, designed from the ground up to have no central authority. It resists censorship, enables individual participants to control their own data, and allows anyone at all to integrate new software into the Gossamer network. Gossamer does not exist, but if it did, the following notes describe what it might look like, and the factors to consider when implementing Gossamer as software. I have made fatal mistakes while writing it; I have not rushed to build it specifically because Twitter, Gossamer's model, is so deeply woven into so many peoples' lives. A successor must make fewer mistakes, not merely different mistakes, and certainly not more mistakes. The following is loosely inspired by Rumor Monger , at \u201cwhole world\u201d scale.","title":"Gossamer: A Decentralized Status-Sharing Network"},{"location":"gossamer/#design-goals","text":"Users must be in control of their own privacy and identity at all times. (This is a major failing with Diaspora, which limits access to personal ownership of data by being hard to run.) Users must be able to communicate without the consent or support of an intermediate authority. Short of being completely offline, Gossamer should be resilient to infrastructural damage. Any functional communication system will be used for illicit purposes. This is an unavoidable consequence of being usable for legitimate purposes without a central authority. Rather than revealing illicit conversations, Gossamer should do what it can to preserve the anonymity and privacy of legitimate ones. All nodes are as equal as possible. The node I use is not more authoritative for messages from me than any other node. You can hear my words from anyone who has heard my words, and I can hear yours from anyone who has heard your words, so long as some variety of authenticity and privacy are maintained. If an identity's secrets are removed, a node should contain no data that correlates the owner with his or her Gossamer identities. Relaying and authoring must be as indistinguishable as possible, to limit the utility of traffic analysis.","title":"Design Goals"},{"location":"gossamer/#public-and-private-information","text":"Every piece of data Gossamer uses, either internally or to communicate with other ndoes, is classified as either public or private . Public information can be communicated to other nodes, and is assumed to be safe if recovered out of band. Private information includes anything which may be used to associate a Gossamer identity with the person who controls it, except as noted below. Gossamer must ensure users understand what information that they provide will be made public, and what will be kept private, so that they can better decide what, if anything, to share and so that they can better make decisions about their own safety and comfort against abusive parties. Internally, Gossamer always stores private information encrypted, and never transmits it to another node. Gossamer must provide a tool to safely obliterate private data.","title":"Public and Private Information"},{"location":"gossamer/#public-information","text":"Details on the role of each piece of information are covered below. Public status updates, obviously. Gossamer exists to permit users to easily share short messages with one another. The opaque form of a user's incoming and outgoing private messages. The users' identities' public keys. (But not their relationship to one another.) Any information the user places in their profile. (This implies that profiles must not be auto-populated from, for example, the user's address book.) The set of identities verified by the user's identity. Any other information Gossamer retains must be private.","title":"Public Information"},{"location":"gossamer/#republishing","text":"Gossamer is built on the assumption that every participant is willing to act as a relay for every other participant. This is a complicated assumption at the human layer. Inevitably, someone will use the Gossamer network to communicate something morally repugnant or deeply illegal: the Silk Road guy, for example, got done for trying to contract someone to commit murder. Every Gossamer node is complicit in delivering those messages to the rest of the network, whether they're in the clear (status updates) or not (private messages). It's unclear how this interacts with the various legal frameworks, moral codes, and other social constructs throughout the world, and it's ethically troubling to put users in that position by default. The strong alternative, that each node only relay content with the controlling user's explicit and ongoing consent, is also troubling: it limits the Gossamer network's ability to deliver messages at all , and exposes information about which identities each node's owner considers interesting and publishable. I don't have an obvious resolution to this. Gossamer's underlying protocol relies on randomly-selected nodes being more likely to propagate a message than to ignore it, because this helps make Gossamer resilient to hostile users, nosy intelligence agencies, and others who believe communication must be restrictable. On the other hand, I'd like not to put a user in Taiwan at risk of legal or social reprisals because a total stranger in Canada decided to post something vile. (This is one of the reasons I haven't built the damn thing yet. Besides being A Lot Of Code, there's no way to shut off Gossamer once more than one node exists, and I want to be sure I've thought through what I'm doing before creating a prototype.)","title":"Republishing"},{"location":"gossamer/#identity-in-the-gossamer-network","text":"Every Gossamer message carries with it an identity . Gossamer identities are backed by public-key cryptography. However, unlike traditional public key systems such as GPG, Gossamer identities provide continuity , rather than authenticity : two Gossamer messages signed by the same key are from the same identity, but there is no inherent guarantee that that identity is legitimate. Gossamer maintains relationships between identities to allow users to verify the identities of one another, and to publish attestations of that to other Gossamer nodes. From this, Gossamer can recover much of GPG's \u201cweb of trust.\u201d TODO : revocation of identities, revocation of verifications. Both are important; novice users are likely to verify people poorly, and there should be a recovery path less drastic than GPG's \u201cyou swore it, you're stuck with it\u201d model. Gossamer encourages users to create additional identities as needed to, for example, support the separation of work and home conversations, or to provide anonymity when discussing reputationally-hazardous topics. Identities are not correlated by the Gossamer codebase. Each identity can optionally include a profile : a block of data describing the person behind the identity. The contents of a profile are chosen by the person holding the private key for an identity, and the profile is attached to every new message created with the corresponding identity. A user can update their profile at will; potentially, every message can be sent with a distinct profile. Gossamer software treats the profile it's seen with the highest timestamp as authoritative, retroactively applying it to old messages.","title":"Identity in the Gossamer Network"},{"location":"gossamer/#multiple-devices-and-key-security","text":"A Gossamer identity is entirely contained in its private key. An identity's key must be stored safely, either using the host operating system's key management facilities or using a carefully-designed key store. Keys must not hit long-term storage unprotected; this may involve careful integration with the underlying OS's memory management facilities to avoid, eg., placing identities in swap. This is necessary to protect users from having their identities recovered against their will via, for example, hard drive forensics. Gossamer allows keys to be exported into password-encrypted archive files, which can be loaded into other Gossamer applications to allow them to share the same identity. GOSSAMER MUST TREAT THESE FILES WITH EXTREME CARE, BECAUSE USERS PROBABLY WON'T . Identity keys protect the user's Gossamer identity, but they also protect the user's private messages (see below) and other potentially identifying data. The export format must be designed to be as resilient as possible, and Gossamer's software must take care to ensure that \u201cused\u201d identity files are automatically destroyed safely wherever possible and to discourage users from following practices that weaken their own safety unknowingly. Exported identity files are intrinsically vulnerable to offline brute-force attacks; once obtained, an attacker can try any of the worryingly common passwords at will, and can easily validate a password by using the recovered keys to regenerate some known fact about the original, such as a verification or a message signature. This implies that exported identities must use a key derivation system which has a high computational cost and which is believed to be resilient to, for example, GPU-accelerated cracking. Secure deletion is a Hard Problem; where possible, Gossamer must use operating system-provided facilities for securely destroying files.","title":"Multiple Devices and Key Security"},{"location":"gossamer/#status-messages","text":"Status messages are messages visible to any interested Gossamer users. These are the primary purpose of Gossamer. Each contains up to 140 Unicode characters, a markup section allowing Gossamer to attach URLs and metadata (including Gossamer locators) to the text, and an attachments section carrying arbitrary MIME blobs of limited total size. All three sections are canonicalized ( TODO : how?) and signed by the publishing identity's private key. The public key, the identity's most recent profile, and the signed status message are combined into a single Gossamer message and injected into the user's Gossamer node exactly as if it had arrived from another node. Each Gossamer node maintains a follow list of identities whose messages the user is interested in seeing. When Gossamer receives a novel status message during a gossip exchange, it displays it to the user if and only if its identity is on the node's follow list. Otherwise, the message is not displayed, but will be shared onwards with other nodes. In this way, every Gossamer node acts as a relay for every other Gossamer node. If Gossamer receives a message signed by an identity it has seen attestations for, it attaches those attestations to the message before delivering them onwards. In this way, users' verifications of one another's identity spread through the network organically.","title":"Status Messages"},{"location":"gossamer/#private-messages","text":"Gossamer can optionally encrypt messages, allowing users to send one another private messages. These messages are carried over the Gossamer network as normal, but only nodes holding the appropriate identity key can decrypt them and display them to the user. (At any given time, most Gossamer nodes hold many private messages they cannot decrypt.) Private messages do not carry the author's identity or full profile in the clear. The author's bare identity is included in the encrypted part of the message, to allow the intended recipient to identify the sender. TODO : sign-then-encrypt, or encrypt-then-sign? If sign-then-encrypt, are private messages exempted from the \u201cdrop broken messages\u201d rule above?","title":"Private Messages"},{"location":"gossamer/#following-users","text":"Each Gossamer node maintains a database of followed identities. (This may or may not include the owner's own identity.) Any message stored in the node published by an identity in this database will be shown to the user in a timeline-esque view. Gossamer's follow list is purely local , and is not shared between nodes even if they have identities in common. The follow list is additionally stored encrypted using the node's identities (any one identity is sufficient to recover the list), to ensure that the follow list is not easily available to others without the node owner's permission. Exercises such as Finding Paul Revere have shown that the collection of graph edges showing who communicates with whom can often be sufficient to map identities into people. Gossamer attempts to restrict access to this data, believing it is not the network's place to know who follows who.","title":"Following Users"},{"location":"gossamer/#verified-identities","text":"Gossamer allows identities to sign one anothers' public keys. These signatures form verifications . Gossamer considers an identity verified if any of the following hold: Gossamer has access to the identity key for the identity itself. Gossamer has access to the identity key for at least one of the identity's verifications. The identity is signed by at least three (todo: or however many, I didn't do the arithmetic yet) verified identities. Verified identities are marked in the user interface to make it obvious to the user whether a message is from a known friend or from an unknown identity. Gossamer allows users to sign new verifications for any identity they have seen. These verifications are initially stored locally, but will be published as messages transit the node as described below. Verification is a public fact: everyone can see which identities have verified which other identities. This is a potentially very powerful tool for reassociating identities with real-world people; Gossamer must make this clear to users. (I'm pretty sure you could find me, personally, just by watching whose identities I verify.) Each Gossamer node maintains a database of every verification it has ever seen or generated. If the node receives a message from an identity that appears in the verification database, and if the message is under some total size, Gossamer appends verifications from its database to the message before reinjecting it into the network. This allows verifications to propagate through","title":"Verified Identities"},{"location":"gossamer/#blocking-users","text":"Any social network will attract hostile users who wish to disrupt the network or abuse its participants. Users must be able to filter out these users, and must not provide too much feedback to blocked users that could otherwise be used to circumvent blocks. Each Gossamer node maintains a database of blocked identities. Any message from an identity in this database, or from an identity that is verified by three or more identities in this database, will automatically be filtered out from display. (Additionally, transitively-blocked users will automatically be added to the block database. Blocking is contagious.) ( TODO : should Gossamer drop blocked messages? How does that interact with the inevitable \u201cshared blocklist\u201d systems that arise in any social network?) As with the follow list, the block database is encrypted using the node's identities. Gossamer encourages users to create new identities as often as they see fit and attempts to separate identities from one another as much as possible. This is fundamentally incompatible with strong blocking. It will always be possible for a newly-created identity to deliver at least one message before being blocked. This is a major design problem ; advice encouraged.","title":"Blocking Users"},{"location":"gossamer/#gossamer-network-primitives","text":"The Gossamer network is built around a gossip protocol, wherein nodes connect to one another periodically to exchange messages with one another. Connections occur over the existing IP internet infrastructure, traversing NAT networks where possible to ensure that users on residential and corporate networks can still participate. Gossamer bootstraps its network using a number of paths: Gossamer nodes in the same broadcast domain discover one another using UDP broadcasts as well as Bonjour/mDNS. Gossamer can generate locator strings, which can be shared \u201cout of band\u201d via email, SMS messages, Twitter, graffiti, etc. Gossamer nodes share knowledge of nodes whenever they exchange messages, to allow the Gossamer network to recover from lost nodes and to permit nodes to remain on the network as \u201cknown\u201d nodes are lost to outages and entropy.","title":"Gossamer Network Primitives"},{"location":"gossamer/#locators","text":"A Gossamer locator is a URL in the g scheme, carrying an encoding of one or more network addresses as well as an encoding of one or more identities (see below). Gossamer's software attempts to determine an appropriate identifier for any identities it holds based on the host computer's network configuration, taking into account issues like NAT traversal wherever possible. TODO : Gossamer and uPNP, what do locators look like? When presented with an identifier, Gossamer offers to follow the identities it contains, and uses the nodes whose addresses it contains to connect to the Gossamer network. This allows new clients to bootstrap into Gossamer, and provides an easy way for users to exchange Gossamer identities to connect to one another later. (Clever readers will note that the address list is actually independent of the identity list.)","title":"Locators"},{"location":"gossamer/#gossip","text":"Each Gossamer node maintains a pair of \u201cfreshness\u201d databases, associating some information with a freshness score (expressed as an integer). One freshness database holds the addresses of known Gossamer nodes, and another holds Gossamer messages. Whenever two Gossamer nodes interact, each sends the other a Gossamer node from its current node database, and a message from its message database. When selecting an item to send for either category, Gossamer uses a random selection that weights towards items with a higher \u201cfreshness\u201d score. ( TODO : how?) When sending a fact, if the receiving node already knows the fact, both nodes decrement that fact's freshness by one. If the receiving node does not already know the fact, the sending node leaves its freshness unaltered, and the receiving node sets its freshness to the freshest possible value. This system encourages nodes to exchange \u201cfresh\u201d facts, then cease exchanging them as the network becomes aware of them. During each exchange, Gossamer nodes send each other one Gossamer node address, and one Gossamer message. Both nodes adjust their freshness databases, as above. If fact exchange fails while communicating with a Gossamer node, both nodes decrement their peer's freshness. Unreliable nodes can continue to initiate connections to other nodes, but will rarely be contacted by other Gossamer nodes. TODO : How do we avoid DDOSing brand-new gossamer nodes with the full might of Gossamer's network? TODO : Can we reuse Bittorrent's DHT system (BEP-5) to avoid having every node know the full network topology? TODO : Are node-to-node exchanges encrypted? If so, why and how?","title":"Gossip"},{"location":"gossamer/#authenticity","text":"Gossamer node addresses are not authenticated. Gossamer relies on freshness to avoid delivering excess traffic to systems not participating in the Gossamer network. ( TODO : this is a shit system for avoiding DDOS, though.) Gossamer messages are partially authenticated: each carries with it a public key, and a signature. If the signature cannot be verified with the included public key, it must be discarded immediately and it must not be propagated to other nodes. The node delivering the message may also be penalized by having its freshness reduced in the receiving node's database.","title":"Authenticity"},{"location":"gossamer/#gossip-triggers","text":"Gossamer triggers a new Gossip exchange under the following circumstances: 15 seconds, plus a random jitter between zero and 15 more seconds, elapse since the last exchange attempt. Gossamer completes an exchange wherein it learned a new fact from another node. A user injects a fact into Gossamer directly. Gossamer exchanges that fail, or that deliver only already-known facts, do not trigger further exchanges immediately. TODO : how do we prevent Gossamer from attempting to start an unbounded number of exchanges at the same time?","title":"Gossip Triggers"},{"location":"gossamer/#size","text":"Gossamer must not exhaust the user's disk. Gossamer discards extremely un-fresh messages, attempting to keep the on-disk size of the message database to under 10% of the total local storage, or under a user-configurable threshold. Gossamer rejects over-large messages. Public messages carry with them the author's profile and a potentially large collection of verifications. Messages over some size ( TODO what size?) are discarded on receipt without being stored, and the message exchange is considered to have failed.","title":"Size"},{"location":"gossamer/coda/","text":"A Coda \u00b6 Kit : How would you make a site where the server operator can't get at a user's data, and given handling complaints and the fact that people can still screen cap receipts etc, would you? Is it a valuable goal? Owen : That's what torpedoed my interest in developing gossamer further, honestly meg laid out an abuse case so dismal that I consider the whole concept compromised centralizing the service a little - mastodon-ishly, say - improves the situation a bit, but if they can't get at their users' data their options are limited I think secrecy and republication resilience are kind of non-goals, and the lesson I took is that accountability (and thus locality and continuity of identity) are way more important specifically accountability between community members, not accountability to the operator or to the state","title":"A Coda"},{"location":"gossamer/coda/#a-coda","text":"Kit : How would you make a site where the server operator can't get at a user's data, and given handling complaints and the fact that people can still screen cap receipts etc, would you? Is it a valuable goal? Owen : That's what torpedoed my interest in developing gossamer further, honestly meg laid out an abuse case so dismal that I consider the whole concept compromised centralizing the service a little - mastodon-ishly, say - improves the situation a bit, but if they can't get at their users' data their options are limited I think secrecy and republication resilience are kind of non-goals, and the lesson I took is that accountability (and thus locality and continuity of identity) are way more important specifically accountability between community members, not accountability to the operator or to the state","title":"A Coda"},{"location":"gossamer/mistakes/","text":"Design Mistakes \u00b6 Is Gossamer Up? \u00b6 @megtastique points out that two factors doom the whole design: There's no way to remove content from Gossamer once it's published, and Gossamer can anonymously share images. Combined, these make Gossamer the perfect vehicle for revenge porn and other gendered, sexually-loaded network abuse. This alone is enough to doom the design, as written: even restricting the size of messages to the single kilobyte range still makes it trivial to irrevocably disseminate links to similar content. Protected Feeds? Who Needs Those? \u00b6 Gossamer's design does not carry forward an important Twitter feature: the protected feed. In brief, protected feeds allow people to be choosy about who reads their status updates, without necessarily having to pick and choose who gets to read them on a message by message basis. This is an important privacy control for people who wish to engage with people they know without necessarily disclosing their whereabouts and activities to the world at large. In particular, it's important to vulnerable people because it allows them to create their own safe spaces. Protected feeds are not mere technology, either. Protected feeds carry with them social expectations: Twitter clients often either refuse to copy text from a protected feed, or present a warning when the user tries to copy text, which acts as a very cheap and, apparently, quite effective brake on the casual re-sharing that Twitter encourages for public feeds. DDOS As A Service \u00b6 Gossamer's network protocol converges towards a total graph, where every node knows how to connect to every other node, and new information (new posts) rapidly push out to every single node. If you've ever been privy to the Twitter \u201cfirehose\u201d feed, you'll understand why this is a drastic mistake. Even a moderately successful social network sees on the order of millions of messages a day. Delivering all of this directly to every node all of the time would rapidly drown users in bandwidth charges and render their internet connections completely unusable. Gossamer's design also has no concept of \u201cquiet\u201d periods: every fifteen to thirty seconds, rain or shine, every node is supposed to wake up and exchange data with some other node, regardless of how long it's been since either node in the exchange has seen new data. This very effectively ensures that Gossamer will continue to flood nodes with traffic at all times; the only way to halt the flood is to shut off the Gossamer client. Passive Nodes Matter \u00b6 It's impractical to run an inbound data service on a mobile device. Mobile devices are, by and large, not addressable or reachable by the internet at large. Mobile devices also provide a huge proportion of Twitter's content: the ability to rapidly post photos, location tags, and short text while away from desks, laptops, and formal internet connections is a huge boon for ad-hoc social organization. You can invite someone to the pub from your phone, from in front of the pub. (This interacts ... poorly with the DDOS point, above.) Traffic Analysis \u00b6 When a user enters a new status update or sends a new private message, their Gossamer node immediately forwards it to at least one other node to inject it into the network. This makes unencrypted Gossamer relatively vulnerable to traffic analysis for correlating Gossamer identities with human beings. Someone at a network \u201cpinch point\u201d -- an ISP, or a coffee shop wifi router -- can monitor Gossamer traffic entering and exiting nodes on their network and easily identify which nodes originated which messages, and thus which nodes have access to which identities. This seriously compromises the effectiveness of Gossamer's decentralized, self-certifying identities.","title":"Design Mistakes"},{"location":"gossamer/mistakes/#design-mistakes","text":"","title":"Design Mistakes"},{"location":"gossamer/mistakes/#is-gossamer-up","text":"@megtastique points out that two factors doom the whole design: There's no way to remove content from Gossamer once it's published, and Gossamer can anonymously share images. Combined, these make Gossamer the perfect vehicle for revenge porn and other gendered, sexually-loaded network abuse. This alone is enough to doom the design, as written: even restricting the size of messages to the single kilobyte range still makes it trivial to irrevocably disseminate links to similar content.","title":"Is Gossamer Up?"},{"location":"gossamer/mistakes/#protected-feeds-who-needs-those","text":"Gossamer's design does not carry forward an important Twitter feature: the protected feed. In brief, protected feeds allow people to be choosy about who reads their status updates, without necessarily having to pick and choose who gets to read them on a message by message basis. This is an important privacy control for people who wish to engage with people they know without necessarily disclosing their whereabouts and activities to the world at large. In particular, it's important to vulnerable people because it allows them to create their own safe spaces. Protected feeds are not mere technology, either. Protected feeds carry with them social expectations: Twitter clients often either refuse to copy text from a protected feed, or present a warning when the user tries to copy text, which acts as a very cheap and, apparently, quite effective brake on the casual re-sharing that Twitter encourages for public feeds.","title":"Protected Feeds? Who Needs Those?"},{"location":"gossamer/mistakes/#ddos-as-a-service","text":"Gossamer's network protocol converges towards a total graph, where every node knows how to connect to every other node, and new information (new posts) rapidly push out to every single node. If you've ever been privy to the Twitter \u201cfirehose\u201d feed, you'll understand why this is a drastic mistake. Even a moderately successful social network sees on the order of millions of messages a day. Delivering all of this directly to every node all of the time would rapidly drown users in bandwidth charges and render their internet connections completely unusable. Gossamer's design also has no concept of \u201cquiet\u201d periods: every fifteen to thirty seconds, rain or shine, every node is supposed to wake up and exchange data with some other node, regardless of how long it's been since either node in the exchange has seen new data. This very effectively ensures that Gossamer will continue to flood nodes with traffic at all times; the only way to halt the flood is to shut off the Gossamer client.","title":"DDOS As A Service"},{"location":"gossamer/mistakes/#passive-nodes-matter","text":"It's impractical to run an inbound data service on a mobile device. Mobile devices are, by and large, not addressable or reachable by the internet at large. Mobile devices also provide a huge proportion of Twitter's content: the ability to rapidly post photos, location tags, and short text while away from desks, laptops, and formal internet connections is a huge boon for ad-hoc social organization. You can invite someone to the pub from your phone, from in front of the pub. (This interacts ... poorly with the DDOS point, above.)","title":"Passive Nodes Matter"},{"location":"gossamer/mistakes/#traffic-analysis","text":"When a user enters a new status update or sends a new private message, their Gossamer node immediately forwards it to at least one other node to inject it into the network. This makes unencrypted Gossamer relatively vulnerable to traffic analysis for correlating Gossamer identities with human beings. Someone at a network \u201cpinch point\u201d -- an ISP, or a coffee shop wifi router -- can monitor Gossamer traffic entering and exiting nodes on their network and easily identify which nodes originated which messages, and thus which nodes have access to which identities. This seriously compromises the effectiveness of Gossamer's decentralized, self-certifying identities.","title":"Traffic Analysis"},{"location":"nomic/","text":"Nomic \u00b6 Nomic is a game invented in 1982 by Peter Suber, as an appendix to his PhD thesis The Paradox of Self-Amendment . In Nomic, the primary move available to the players is to change the rules of the game in a structured way. Nomic itself was intended as a minimalist study of procedural law, but it has been played very successfully by many groups over the years. I first played Nomic through Agora , a long-running Nomic of a heavily procedural bent (as opposed to variants like BlogNomic, that have developed in much more whimsical directions). I've found the game, and the communities that have sprung up around the game, deeply fascinating as a way to examine how groups reach consensus and exercise decisions. I briefly experimented with the notion of running a procedural Nomic - a mini-Agora - via Github, and produced two documents: Notes Towards Initial Rules for a Github Nomic Github Nomic Rules","title":"Nomic"},{"location":"nomic/#nomic","text":"Nomic is a game invented in 1982 by Peter Suber, as an appendix to his PhD thesis The Paradox of Self-Amendment . In Nomic, the primary move available to the players is to change the rules of the game in a structured way. Nomic itself was intended as a minimalist study of procedural law, but it has been played very successfully by many groups over the years. I first played Nomic through Agora , a long-running Nomic of a heavily procedural bent (as opposed to variants like BlogNomic, that have developed in much more whimsical directions). I've found the game, and the communities that have sprung up around the game, deeply fascinating as a way to examine how groups reach consensus and exercise decisions. I briefly experimented with the notion of running a procedural Nomic - a mini-Agora - via Github, and produced two documents: Notes Towards Initial Rules for a Github Nomic Github Nomic Rules","title":"Nomic"},{"location":"nomic/notes/","text":"Notes Towards Initial Rules for a Github Nomic \u00b6 This document is not part of the rules of a Nomic, and is present solely as a guide to the design of this initial ruleset , for play on Github. It should be removed before the game starts, and at no time should it be consulted to guide gameplay directly. Peter Suber's Nomic is a game of rule-making for one or more players. For details on the rationale behind the game and the reasons the game might be interesting, see Suber's own description. Changes from Suber's Rules \u00b6 Format \u00b6 I've marked up Suber's rules into Markdown, one of Github's \u201cnative\u201d text markup formats. This highly-structured format produces quite readable results when viewed through the Github website, and allows useful things like HTML links that point to specific rules. I've also made some diff-friendliness choices around the structure of those Markdown documents. For want of a better idea, the source documents are line-broken with one sentence per line, so that diffs naturally span whole sentences rather than arbitrarily-wrapped text (or unwrapped text). Since Github automatically recombines sequences of non-blank lines into a single HTML paragraph, the rendering on the web site is still quite readable. I have not codified this format in the rules themselves. Asynchrony \u00b6 In its original form, Nomic is appropriate for face-to-face play. The rules assume that it is practical for the players to identify one another using out-of-game context, and that it is practical for the players to take turns. Each player is expected to wait indefinitely (or, more likely, to apply non-game social pressure) if the preceding player takes inordinately long to complete their turn. Similarly, Judgement interrupts the flow of game play and brings turns to a stop. This Nomic is to be played on Github, and the players are not likely to be present simultaneously, or to be willing to wait indefinitely. It's possible for Suber's original Nomic rules to be amended, following themselves, into a form suitable for asynchronous play. This has happened several times: for examples, see Agora and BlogNomic , though there are a multitude of others. However, this process of amendment takes time , and, starting from Suber's initial rules, would require a period of one-turn-at-a-time rule-changes before the game could be played more naturally in the Github format. This period is not very interesting, and is incredibly demanding of the initial players' attention spans. In the interests of preserving the players' time, I have modified Suber's initial ruleset to replace sequential play with a simple asynchronous model of play. In summary: Every player can begin a turn at any time, even during another player's (or players') turn, so long as they aren't already taking a turn. Actions can be resolved in any order, depending on which proposals players choose to vote on, and in what order. The initial rules allow for players to end their turns without gathering every vote, once gameplay has proceeded far enough for non-unanimous votes to be possible. I have attempted to leave the rules as close to Suber's original rules as possible otherwise while implementing this change to the initial ruleset. I have faith that the process of playing Nomic will correct any deficiencies, or, failing that, will clearly identify where these changes break the game entirely. I have, as far as I am able, emulated Suber's preference for succinctness over thoroughness, and resisted the urge to fix or clarify rules even where defects seem obvious to me. In spite of my temptation to remove it, I have even left the notion of \u201cwinning\u201d intact. Rule-numbering \u00b6 The intent of this Nomic is to explore the suitability of Github's suite of tools for proposing, reviewing, and accepting changes to a corpus of text are suitable for self-governed rulemaking processes, as modelled by Nomic. Note that this is a test of Github, not of Git: it is appropriate and intended that the players rely on non-Git elements of Github's workflow (issues, wiki pages, Github Pages, and so on), and similarly it is appropriate and intended that the authentic copy of the game in play is the Github project hosting it, not the Git repo the project contains, and certainly not forks of the project or other clones of the repository. To support this intention, I have re-labelled the initial rules with negative numbers, rather than digits, so that proposals can be numbered starting from 1 without colliding with existing rules, and so that they can be numbered by their Pull Requests and Github issue numbers. (A previous version of these rules used Roman numerals for the initial rules. However, correctly accounting for the priority of new rules over initial rules, following Suber, required more changes than I was comfortable making to Suber's ruleset.) I have made it explicit in these initial rules that Github, not the players, assigns numbers to proposals. This is the only rule which mentions Github by name. I have not explicitly specified that the proposals should be implemented through pull requests; this is an intentional opportunity for player creativity. Projects & Ideas \u00b6 A small personal collection of other ideas to explore: Repeal or replace the victory criteria entirely \u00b6 \u201cWinning\u201d is not an objective I'm personally interested in, and Suber's race to 200 points by popularity of proposal is structurally quite dull. If the game is to have a victory condition, it should be built from the ground up to meet the players' motivations, rather than being retrofitted onto the points-based system. Codify the use of Git commits, rather than prose, for rules-changes \u00b6 This is unstated in this ruleset, despite being part of my intention for playing. So is the relationship between proposals and the Git repository underpinning the Github project hosting the game. Clarify the immigration and exit procedures \u00b6 The question of who the players are , or how one becomes a player, is left intentionally vague. In Suber's original rules, it appears that the players are those who are engaged in playing the game: tautological on paper, but inherently obvious by simple observation of the playing-space. On Github, the answer to this question may not be so simple. A public repository is visible to anyone with an internet connection, and will accept proposed pull requests (and issue reports) equally freely. This suggests that either everyone is, inherently, a player, or that player-ness is somehow a function of engaging with the game. I leave it to the players to resolve this situation to their own satisfaction, but my suggestion is to track player-ness using repository collaborators or organization member accounts. Figure out how to regulate the use of Github features \u00b6 Nomic, as written, largely revolves around sequential proposals. That's fine as far as it goes, but Github has a very wide array of project management features - and that set of features changes over time, outside the control of the players, as Github roll out improvements (and, sometimes, break things). Features of probable interest: The gh-pages branch and associated web site. Issue and pull request tagging and approval settings. Third-party integrations. Whether to store non-rule state, as such arises, in the repository, or in the wiki, or elsewhere. Pull request reactions and approvals. The mutability of most Github features. Expand the rules-change process to permit a single proposal to amend many rules \u00b6 This is a standard rules patch, as Suber's initial rule-set is (I believe intentionally) very restrictive. This may turn out to be less relevant on Github, if players are allowed to submit turns in rapid succession with themselves. Transition from immediate amendment to a system of sessions \u00b6 Why not? Parliamentary procedure is fun, right? In an asynchronous environment, the discrete phases of a session system (where proposals are gathered, then debated, then voted upon, then enacted as a unit) might be a better fit for the Github mode of play. Evaluate other models of proposal vetting besides majority vote \u00b6 Github open source projects regularly have a small core team of maintainers supporting a larger group of users. Is it possible to mirror this structure in Nomic? Is it wise to do so? I suspect this is only possible with an inordinately large number of players, but Github could, at least in principle, support that number of players. Note that this is a fairly standard Nomic passtime.","title":"Notes Towards Initial Rules for a Github Nomic"},{"location":"nomic/notes/#notes-towards-initial-rules-for-a-github-nomic","text":"This document is not part of the rules of a Nomic, and is present solely as a guide to the design of this initial ruleset , for play on Github. It should be removed before the game starts, and at no time should it be consulted to guide gameplay directly. Peter Suber's Nomic is a game of rule-making for one or more players. For details on the rationale behind the game and the reasons the game might be interesting, see Suber's own description.","title":"Notes Towards Initial Rules for a Github Nomic"},{"location":"nomic/notes/#changes-from-subers-rules","text":"","title":"Changes from Suber's Rules"},{"location":"nomic/notes/#format","text":"I've marked up Suber's rules into Markdown, one of Github's \u201cnative\u201d text markup formats. This highly-structured format produces quite readable results when viewed through the Github website, and allows useful things like HTML links that point to specific rules. I've also made some diff-friendliness choices around the structure of those Markdown documents. For want of a better idea, the source documents are line-broken with one sentence per line, so that diffs naturally span whole sentences rather than arbitrarily-wrapped text (or unwrapped text). Since Github automatically recombines sequences of non-blank lines into a single HTML paragraph, the rendering on the web site is still quite readable. I have not codified this format in the rules themselves.","title":"Format"},{"location":"nomic/notes/#asynchrony","text":"In its original form, Nomic is appropriate for face-to-face play. The rules assume that it is practical for the players to identify one another using out-of-game context, and that it is practical for the players to take turns. Each player is expected to wait indefinitely (or, more likely, to apply non-game social pressure) if the preceding player takes inordinately long to complete their turn. Similarly, Judgement interrupts the flow of game play and brings turns to a stop. This Nomic is to be played on Github, and the players are not likely to be present simultaneously, or to be willing to wait indefinitely. It's possible for Suber's original Nomic rules to be amended, following themselves, into a form suitable for asynchronous play. This has happened several times: for examples, see Agora and BlogNomic , though there are a multitude of others. However, this process of amendment takes time , and, starting from Suber's initial rules, would require a period of one-turn-at-a-time rule-changes before the game could be played more naturally in the Github format. This period is not very interesting, and is incredibly demanding of the initial players' attention spans. In the interests of preserving the players' time, I have modified Suber's initial ruleset to replace sequential play with a simple asynchronous model of play. In summary: Every player can begin a turn at any time, even during another player's (or players') turn, so long as they aren't already taking a turn. Actions can be resolved in any order, depending on which proposals players choose to vote on, and in what order. The initial rules allow for players to end their turns without gathering every vote, once gameplay has proceeded far enough for non-unanimous votes to be possible. I have attempted to leave the rules as close to Suber's original rules as possible otherwise while implementing this change to the initial ruleset. I have faith that the process of playing Nomic will correct any deficiencies, or, failing that, will clearly identify where these changes break the game entirely. I have, as far as I am able, emulated Suber's preference for succinctness over thoroughness, and resisted the urge to fix or clarify rules even where defects seem obvious to me. In spite of my temptation to remove it, I have even left the notion of \u201cwinning\u201d intact.","title":"Asynchrony"},{"location":"nomic/notes/#rule-numbering","text":"The intent of this Nomic is to explore the suitability of Github's suite of tools for proposing, reviewing, and accepting changes to a corpus of text are suitable for self-governed rulemaking processes, as modelled by Nomic. Note that this is a test of Github, not of Git: it is appropriate and intended that the players rely on non-Git elements of Github's workflow (issues, wiki pages, Github Pages, and so on), and similarly it is appropriate and intended that the authentic copy of the game in play is the Github project hosting it, not the Git repo the project contains, and certainly not forks of the project or other clones of the repository. To support this intention, I have re-labelled the initial rules with negative numbers, rather than digits, so that proposals can be numbered starting from 1 without colliding with existing rules, and so that they can be numbered by their Pull Requests and Github issue numbers. (A previous version of these rules used Roman numerals for the initial rules. However, correctly accounting for the priority of new rules over initial rules, following Suber, required more changes than I was comfortable making to Suber's ruleset.) I have made it explicit in these initial rules that Github, not the players, assigns numbers to proposals. This is the only rule which mentions Github by name. I have not explicitly specified that the proposals should be implemented through pull requests; this is an intentional opportunity for player creativity.","title":"Rule-numbering"},{"location":"nomic/notes/#projects-ideas","text":"A small personal collection of other ideas to explore:","title":"Projects &amp; Ideas"},{"location":"nomic/notes/#repeal-or-replace-the-victory-criteria-entirely","text":"\u201cWinning\u201d is not an objective I'm personally interested in, and Suber's race to 200 points by popularity of proposal is structurally quite dull. If the game is to have a victory condition, it should be built from the ground up to meet the players' motivations, rather than being retrofitted onto the points-based system.","title":"Repeal or replace the victory criteria entirely"},{"location":"nomic/notes/#codify-the-use-of-git-commits-rather-than-prose-for-rules-changes","text":"This is unstated in this ruleset, despite being part of my intention for playing. So is the relationship between proposals and the Git repository underpinning the Github project hosting the game.","title":"Codify the use of Git commits, rather than prose, for rules-changes"},{"location":"nomic/notes/#clarify-the-immigration-and-exit-procedures","text":"The question of who the players are , or how one becomes a player, is left intentionally vague. In Suber's original rules, it appears that the players are those who are engaged in playing the game: tautological on paper, but inherently obvious by simple observation of the playing-space. On Github, the answer to this question may not be so simple. A public repository is visible to anyone with an internet connection, and will accept proposed pull requests (and issue reports) equally freely. This suggests that either everyone is, inherently, a player, or that player-ness is somehow a function of engaging with the game. I leave it to the players to resolve this situation to their own satisfaction, but my suggestion is to track player-ness using repository collaborators or organization member accounts.","title":"Clarify the immigration and exit procedures"},{"location":"nomic/notes/#figure-out-how-to-regulate-the-use-of-github-features","text":"Nomic, as written, largely revolves around sequential proposals. That's fine as far as it goes, but Github has a very wide array of project management features - and that set of features changes over time, outside the control of the players, as Github roll out improvements (and, sometimes, break things). Features of probable interest: The gh-pages branch and associated web site. Issue and pull request tagging and approval settings. Third-party integrations. Whether to store non-rule state, as such arises, in the repository, or in the wiki, or elsewhere. Pull request reactions and approvals. The mutability of most Github features.","title":"Figure out how to regulate the use of Github features"},{"location":"nomic/notes/#expand-the-rules-change-process-to-permit-a-single-proposal-to-amend-many-rules","text":"This is a standard rules patch, as Suber's initial rule-set is (I believe intentionally) very restrictive. This may turn out to be less relevant on Github, if players are allowed to submit turns in rapid succession with themselves.","title":"Expand the rules-change process to permit a single proposal to amend many rules"},{"location":"nomic/notes/#transition-from-immediate-amendment-to-a-system-of-sessions","text":"Why not? Parliamentary procedure is fun, right? In an asynchronous environment, the discrete phases of a session system (where proposals are gathered, then debated, then voted upon, then enacted as a unit) might be a better fit for the Github mode of play.","title":"Transition from immediate amendment to a system of sessions"},{"location":"nomic/notes/#evaluate-other-models-of-proposal-vetting-besides-majority-vote","text":"Github open source projects regularly have a small core team of maintainers supporting a larger group of users. Is it possible to mirror this structure in Nomic? Is it wise to do so? I suspect this is only possible with an inordinately large number of players, but Github could, at least in principle, support that number of players. Note that this is a fairly standard Nomic passtime.","title":"Evaluate other models of proposal vetting besides majority vote"},{"location":"nomic/rules/","text":"Github Nomic Rules \u00b6 Immutable Rules \u00b6 Rule -216. \u00b6 All players must always abide by all the rules then in effect, in the form in which they are then in effect. The rules in the Initial Set are in effect whenever a game begins. The Initial Set consists of rules -216 through -201 (immutable) and rules -112 through -101 (mutable). Rule -215. \u00b6 Initially, rules -216 through -201 are immutable, and rules -112 through -101 are mutable. Rules subsequently enacted or transmuted (that is, changed from immutable to mutable or vice versa) may be immutable or mutable regardless of their numbers, and rules in the Initial Set may be transmuted regardless of their numbers. Rule -214. \u00b6 A rule-change is any of the following: the enactment, repeal, or amendment of a mutable rule; the enactment, repeal, or amendment of an amendment of a mutable rule; or the transmutation of an immutable rule into a mutable rule or vice versa. (Note: This definition implies that, at least initially, all new rules are mutable; immutable rules, as long as they are immutable, may not be amended or repealed; mutable rules, as long as they are mutable, may be amended or repealed; any rule of any status may be transmuted; no rule is absolutely immune to change.) Rule -213. \u00b6 All rule-changes proposed in the proper way shall be voted on. They will be adopted if and only if they receive the required number of votes. Rule -212. \u00b6 Every player is an eligible voter. Rule -211. \u00b6 All proposed rule-changes shall be written down before they are voted on. If they are adopted, they shall guide play in the form in which they were voted on. Rule -210. \u00b6 No rule-change may take effect earlier than the moment of the completion of the vote that adopted it, even if its wording explicitly states otherwise. No rule-change may have retroactive application. Rule -209. \u00b6 Each proposed rule-change shall be given a number for reference. The numbers shall be assigned by Github, so that each rule-change proposed in the proper way shall receive the a distinct integer from all prior proposals, whether or not the proposal is adopted. If a rule is repealed and reenacted, it receives the number of the proposal to reenact it. If a rule is amended or transmuted, it receives the number of the proposal to amend or transmute it. If an amendment is amended or repealed, the entire rule of which it is a part receives the number of the proposal to amend or repeal the amendment. Rule -208. \u00b6 Rule-changes that transmute immutable rules into mutable rules may be adopted if and only if the vote is unanimous among the eligible voters. Transmutation shall not be implied, but must be stated explicitly in a proposal to take effect. Rule -207. \u00b6 In a conflict between a mutable and an immutable rule, the immutable rule takes precedence and the mutable rule shall be entirely void. For the purposes of this rule a proposal to transmute an immutable rule does not \"conflict\" with that immutable rule. Rule -206. \u00b6 If a rule-change as proposed is unclear, ambiguous, paradoxical, or destructive of play, or if it arguably consists of two or more rule-changes compounded or is an amendment that makes no difference, or if it is otherwise of questionable value, then the other players may suggest amendments or argue against the proposal before the vote. A reasonable time must be allowed for this debate. The proponent decides the final form in which the proposal is to be voted on and, unless the Judge has been asked to do so, also decides the time to end debate and vote. Rule -205. \u00b6 The state of affairs that constitutes winning may not be altered from achieving n points to any other state of affairs. The magnitude of n and the means of earning points may be changed, and rules that establish a winner when play cannot continue may be enacted and (while they are mutable) be amended or repealed. Rule -204. \u00b6 A player always has the option to forfeit the game rather than continue to play or incur a game penalty. No penalty worse than losing, in the judgment of the player to incur it, may be imposed. Rule -203. \u00b6 There must always be at least one mutable rule. The adoption of rule-changes must never become completely impermissible. Rule -202. \u00b6 Rule-changes that affect rules needed to allow or apply rule-changes are as permissible as other rule-changes. Even rule-changes that amend or repeal their own authority are permissible. No rule-change or type of move is impermissible solely on account of the self-reference or self-application of a rule. Rule -201. \u00b6 Whatever is not prohibited or regulated by a rule is permitted and unregulated, with the sole exception of changing the rules, which is permitted only when a rule or set of rules explicitly or implicitly permits it. Mutable Rules \u00b6 Rule -112. \u00b6 A player may begin a turn at any time that suits them. Turns may overlap: one player may begin a turn while another player's is in progress. No player may begin a turn unless all of their previous turns have ended. All players begin with zero points. Rule -111. \u00b6 One turn consists of two parts in this order: proposing one rule-change and having it voted on, and scoring the proposal and adding that score to the proposing player's score. A proposal is scored by taking the proposal number, adding nine to it, multiplying the result by the fraction of favourable votes the proposal received, and rounding that result to the nearest integer. (This scoring system yields a number between 0 and 10 for the first proposal, with the upper limit increasing by one for each new proposal; more points are awarded for more popular proposals.) Rule -110. \u00b6 A rule-change is adopted if and only if the vote in favour is unanimous among the eligible voters. If this rule is not amended before each player has had two turns, it automatically changes to require only a simple majority. If and when rule-changes can only be adopted unanimously, the voting may be ended as soon as an opposing vote is counted. If and when rule-changes can be adopted by simple majority, the voting may be ended as soon as a simple majority in favour or a simple majority against is counted. Rule -109. \u00b6 If and when rule-changes can be adopted without unanimity, the players who vote against winning proposals shall receive 10 points each. Rule -108. \u00b6 An adopted rule-change takes full effect at the moment of the completion of the vote that adopted it. Rule -107. \u00b6 When a proposed rule-change is defeated, the player who proposed it loses 10 points. Rule -106. \u00b6 Each player always has exactly one vote. Rule -105. \u00b6 The winner is the first player to achieve 200 (positive) points. Rule -104. \u00b6 At no time may there be more than 25 mutable rules. Rule -103. \u00b6 If two or more mutable rules conflict with one another, or if two or more immutable rules conflict with one another, then the rule with the lowest ordinal number takes precedence. If at least one of the rules in conflict explicitly says of itself that it defers to another rule (or type of rule) or takes precedence over another rule (or type of rule), then such provisions shall supersede the numerical method for determining precedence. If two or more rules claim to take precedence over one another or to defer to one another, then the numerical method again governs. Rule -102. \u00b6 If players disagree about the legality of a move or the interpretation or application of a rule, then the player moving may ask any other player to be the Judge and decide the question. Disagreement for the purposes of this rule may be created by the insistence of any player. This process is called invoking Judgment. When Judgment has been invoked, no player may begin his or her turn without the consent of a majority of the other players. The Judge's Judgment may be overruled only by a unanimous vote of the other players taken before the next turn is begun. If a Judge's Judgment is overruled, then the Judge may ask any player other than the moving player, and other than any player who has already been the Judge for the question, to become the new Judge for the question, and so on, except that no player is to be Judge during his or her own turn or during the turn of a team-mate. Unless a Judge is overruled, one Judge settles all questions arising from the game until the next turn is begun, including questions as to his or her own legitimacy and jurisdiction as Judge. New Judges are not bound by the decisions of old Judges. New Judges may, however, settle only those questions on which the players currently disagree and that affect the completion of the turn in which Judgment was invoked. All decisions by Judges shall be in accordance with all the rules then in effect; but when the rules are silent, inconsistent, or unclear on the point at issue, then the Judge shall consider game-custom and the spirit of the game before applying other standards. Rule -101. \u00b6 If the rules are changed so that further play is impossible, or if the legality of a move cannot be determined with finality, or if by the Judge's best reasoning, not overruled, a move appears equally legal and illegal, then the first player unable to complete a turn is the winner. This rule takes precedence over every other rule determining the winner.","title":"Github Nomic Rules"},{"location":"nomic/rules/#github-nomic-rules","text":"","title":"Github Nomic Rules"},{"location":"nomic/rules/#immutable-rules","text":"","title":"Immutable Rules"},{"location":"nomic/rules/#rule-216","text":"All players must always abide by all the rules then in effect, in the form in which they are then in effect. The rules in the Initial Set are in effect whenever a game begins. The Initial Set consists of rules -216 through -201 (immutable) and rules -112 through -101 (mutable).","title":"Rule -216."},{"location":"nomic/rules/#rule-215","text":"Initially, rules -216 through -201 are immutable, and rules -112 through -101 are mutable. Rules subsequently enacted or transmuted (that is, changed from immutable to mutable or vice versa) may be immutable or mutable regardless of their numbers, and rules in the Initial Set may be transmuted regardless of their numbers.","title":"Rule -215."},{"location":"nomic/rules/#rule-214","text":"A rule-change is any of the following: the enactment, repeal, or amendment of a mutable rule; the enactment, repeal, or amendment of an amendment of a mutable rule; or the transmutation of an immutable rule into a mutable rule or vice versa. (Note: This definition implies that, at least initially, all new rules are mutable; immutable rules, as long as they are immutable, may not be amended or repealed; mutable rules, as long as they are mutable, may be amended or repealed; any rule of any status may be transmuted; no rule is absolutely immune to change.)","title":"Rule -214."},{"location":"nomic/rules/#rule-213","text":"All rule-changes proposed in the proper way shall be voted on. They will be adopted if and only if they receive the required number of votes.","title":"Rule -213."},{"location":"nomic/rules/#rule-212","text":"Every player is an eligible voter.","title":"Rule -212."},{"location":"nomic/rules/#rule-211","text":"All proposed rule-changes shall be written down before they are voted on. If they are adopted, they shall guide play in the form in which they were voted on.","title":"Rule -211."},{"location":"nomic/rules/#rule-210","text":"No rule-change may take effect earlier than the moment of the completion of the vote that adopted it, even if its wording explicitly states otherwise. No rule-change may have retroactive application.","title":"Rule -210."},{"location":"nomic/rules/#rule-209","text":"Each proposed rule-change shall be given a number for reference. The numbers shall be assigned by Github, so that each rule-change proposed in the proper way shall receive the a distinct integer from all prior proposals, whether or not the proposal is adopted. If a rule is repealed and reenacted, it receives the number of the proposal to reenact it. If a rule is amended or transmuted, it receives the number of the proposal to amend or transmute it. If an amendment is amended or repealed, the entire rule of which it is a part receives the number of the proposal to amend or repeal the amendment.","title":"Rule -209."},{"location":"nomic/rules/#rule-208","text":"Rule-changes that transmute immutable rules into mutable rules may be adopted if and only if the vote is unanimous among the eligible voters. Transmutation shall not be implied, but must be stated explicitly in a proposal to take effect.","title":"Rule -208."},{"location":"nomic/rules/#rule-207","text":"In a conflict between a mutable and an immutable rule, the immutable rule takes precedence and the mutable rule shall be entirely void. For the purposes of this rule a proposal to transmute an immutable rule does not \"conflict\" with that immutable rule.","title":"Rule -207."},{"location":"nomic/rules/#rule-206","text":"If a rule-change as proposed is unclear, ambiguous, paradoxical, or destructive of play, or if it arguably consists of two or more rule-changes compounded or is an amendment that makes no difference, or if it is otherwise of questionable value, then the other players may suggest amendments or argue against the proposal before the vote. A reasonable time must be allowed for this debate. The proponent decides the final form in which the proposal is to be voted on and, unless the Judge has been asked to do so, also decides the time to end debate and vote.","title":"Rule -206."},{"location":"nomic/rules/#rule-205","text":"The state of affairs that constitutes winning may not be altered from achieving n points to any other state of affairs. The magnitude of n and the means of earning points may be changed, and rules that establish a winner when play cannot continue may be enacted and (while they are mutable) be amended or repealed.","title":"Rule -205."},{"location":"nomic/rules/#rule-204","text":"A player always has the option to forfeit the game rather than continue to play or incur a game penalty. No penalty worse than losing, in the judgment of the player to incur it, may be imposed.","title":"Rule -204."},{"location":"nomic/rules/#rule-203","text":"There must always be at least one mutable rule. The adoption of rule-changes must never become completely impermissible.","title":"Rule -203."},{"location":"nomic/rules/#rule-202","text":"Rule-changes that affect rules needed to allow or apply rule-changes are as permissible as other rule-changes. Even rule-changes that amend or repeal their own authority are permissible. No rule-change or type of move is impermissible solely on account of the self-reference or self-application of a rule.","title":"Rule -202."},{"location":"nomic/rules/#rule-201","text":"Whatever is not prohibited or regulated by a rule is permitted and unregulated, with the sole exception of changing the rules, which is permitted only when a rule or set of rules explicitly or implicitly permits it.","title":"Rule -201."},{"location":"nomic/rules/#mutable-rules","text":"","title":"Mutable Rules"},{"location":"nomic/rules/#rule-112","text":"A player may begin a turn at any time that suits them. Turns may overlap: one player may begin a turn while another player's is in progress. No player may begin a turn unless all of their previous turns have ended. All players begin with zero points.","title":"Rule -112."},{"location":"nomic/rules/#rule-111","text":"One turn consists of two parts in this order: proposing one rule-change and having it voted on, and scoring the proposal and adding that score to the proposing player's score. A proposal is scored by taking the proposal number, adding nine to it, multiplying the result by the fraction of favourable votes the proposal received, and rounding that result to the nearest integer. (This scoring system yields a number between 0 and 10 for the first proposal, with the upper limit increasing by one for each new proposal; more points are awarded for more popular proposals.)","title":"Rule -111."},{"location":"nomic/rules/#rule-110","text":"A rule-change is adopted if and only if the vote in favour is unanimous among the eligible voters. If this rule is not amended before each player has had two turns, it automatically changes to require only a simple majority. If and when rule-changes can only be adopted unanimously, the voting may be ended as soon as an opposing vote is counted. If and when rule-changes can be adopted by simple majority, the voting may be ended as soon as a simple majority in favour or a simple majority against is counted.","title":"Rule -110."},{"location":"nomic/rules/#rule-109","text":"If and when rule-changes can be adopted without unanimity, the players who vote against winning proposals shall receive 10 points each.","title":"Rule -109."},{"location":"nomic/rules/#rule-108","text":"An adopted rule-change takes full effect at the moment of the completion of the vote that adopted it.","title":"Rule -108."},{"location":"nomic/rules/#rule-107","text":"When a proposed rule-change is defeated, the player who proposed it loses 10 points.","title":"Rule -107."},{"location":"nomic/rules/#rule-106","text":"Each player always has exactly one vote.","title":"Rule -106."},{"location":"nomic/rules/#rule-105","text":"The winner is the first player to achieve 200 (positive) points.","title":"Rule -105."},{"location":"nomic/rules/#rule-104","text":"At no time may there be more than 25 mutable rules.","title":"Rule -104."},{"location":"nomic/rules/#rule-103","text":"If two or more mutable rules conflict with one another, or if two or more immutable rules conflict with one another, then the rule with the lowest ordinal number takes precedence. If at least one of the rules in conflict explicitly says of itself that it defers to another rule (or type of rule) or takes precedence over another rule (or type of rule), then such provisions shall supersede the numerical method for determining precedence. If two or more rules claim to take precedence over one another or to defer to one another, then the numerical method again governs.","title":"Rule -103."},{"location":"nomic/rules/#rule-102","text":"If players disagree about the legality of a move or the interpretation or application of a rule, then the player moving may ask any other player to be the Judge and decide the question. Disagreement for the purposes of this rule may be created by the insistence of any player. This process is called invoking Judgment. When Judgment has been invoked, no player may begin his or her turn without the consent of a majority of the other players. The Judge's Judgment may be overruled only by a unanimous vote of the other players taken before the next turn is begun. If a Judge's Judgment is overruled, then the Judge may ask any player other than the moving player, and other than any player who has already been the Judge for the question, to become the new Judge for the question, and so on, except that no player is to be Judge during his or her own turn or during the turn of a team-mate. Unless a Judge is overruled, one Judge settles all questions arising from the game until the next turn is begun, including questions as to his or her own legitimacy and jurisdiction as Judge. New Judges are not bound by the decisions of old Judges. New Judges may, however, settle only those questions on which the players currently disagree and that affect the completion of the turn in which Judgment was invoked. All decisions by Judges shall be in accordance with all the rules then in effect; but when the rules are silent, inconsistent, or unclear on the point at issue, then the Judge shall consider game-custom and the spirit of the game before applying other standards.","title":"Rule -102."},{"location":"nomic/rules/#rule-101","text":"If the rules are changed so that further play is impossible, or if the legality of a move cannot be determined with finality, or if by the Judge's best reasoning, not overruled, a move appears equally legal and illegal, then the first player unable to complete a turn is the winner. This rule takes precedence over every other rule determining the winner.","title":"Rule -101."}]}